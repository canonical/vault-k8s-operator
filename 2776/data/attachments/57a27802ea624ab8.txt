[32mINFO    [0m juju.model:model.py:3211 Waiting for model:
  vault-b/0 [idle] active: 
  vault-b/2 [idle] active: 
  vault-b/1 [idle] active: 
[32mINFO    [0m juju.model:model.py:3211 Waiting for model:
  vault-b/0 [idle] active: 
  vault-b/2 [idle] active: 
  vault-b/1 [idle] active:
[32mINFO    [0m pytest_operator.plugin:plugin.py:929 Model status:

Model                  Controller                Cloud/Region        Version  SLA          Timestamp
test-integration-tz99  github-pr-6b99b-microk8s  microk8s/localhost  3.6.2    unsupported  17:10:29Z

App        Version  Status  Scale  Charm      Channel  Rev  Address        Exposed  Message
vault-b             active      3  vault-k8s             1  10.152.183.90  no       
vault-k8s           active      3  vault-k8s             0  10.152.183.37  no       

Unit          Workload  Agent      Address     Ports  Message
vault-b/0*    active    executing  10.1.53.11         
vault-b/1     active    executing  10.1.53.4          
vault-b/2     active    executing  10.1.53.10         
vault-k8s/0*  active    executing  10.1.53.17         
vault-k8s/1   active    executing  10.1.53.25         
vault-k8s/2   active    executing  10.1.53.23         

[32mINFO    [0m pytest_operator.plugin:plugin.py:935 Juju error logs:

unit-vault-k8s-1: 16:38:09 ERROR unit.vault-k8s/1.juju-log [vault_client] Error while checking Vault health status: HTTPSConnectionPool(host='vault-k8s-1.vault-k8s-endpoints.test-integration-tz99.svc.cluster.local', port=8200): Max retries exceeded with url: /v1/sys/health (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dc30f1b9450>: Failed to establish a new connection: [Errno 111] Connection refused'))
unit-vault-k8s-3: 16:39:16 ERROR unit.vault-k8s/3.juju-log vault-peers:0: Raft cluster is not healthy. {'failure_tolerance': 1, 'healthy': False, 'leader': 'test-integration-tz99-vault-k8s/0', 'servers': {'test-integration-tz99-vault-k8s/0': {'id': 'test-integration-tz99-vault-k8s/0', 'name': 'test-integration-tz99-vault-k8s/0', 'address': 'vault-k8s-0.vault-k8s-endpoints.test-integration-tz99.svc.cluster.local:8201', 'node_status': 'alive', 'last_contact': '0s', 'last_term': 3, 'last_index': 140, 'healthy': True, 'stable_since': '2025-02-02T16:35:04.078855559Z', 'status': 'leader', 'version': '1.16.3', 'node_type': 'voter'}, 'test-integration-tz99-vault-k8s/1': {'id': 'test-integration-tz99-vault-k8s/1', 'name': 'test-integration-tz99-vault-k8s/1', 'address': 'vault-k8s-1.vault-k8s-endpoints.test-integration-tz99.svc.cluster.local:8201', 'node_status': 'alive', 'last_contact': '2.177397545s', 'last_term': 3, 'last_index': 138, 'healthy': True, 'stable_since': '2025-02-02T16:36:18.079017731Z', 'status': 'voter', 'version': '1.16.3', 'node_type': 'voter'}, 'test-integration-tz99-vault-k8s/2': {'id': 'test-integration-tz99-vault-k8s/2', 'name': 'test-integration-tz99-vault-k8s/2', 'address': 'vault-k8s-2.vault-k8s-endpoints.test-integration-tz99.svc.cluster.local:8201', 'node_status': 'alive', 'last_contact': '2.57881906s', 'last_term': 3, 'last_index': 138, 'healthy': True, 'stable_since': '2025-02-02T16:36:20.079888297Z', 'status': 'voter', 'version': '1.16.3', 'node_type': 'voter'}, 'test-integration-tz99-vault-k8s/3': {'id': 'test-integration-tz99-vault-k8s/3', 'name': 'test-integration-tz99-vault-k8s/3', 'address': 'vault-k8s-3.vault-k8s-endpoints.test-integration-tz99.svc.cluster.local:8201', 'node_status': 'alive', 'last_contact': '1.267799498s', 'last_term': 0, 'last_index': 0, 'healthy': False, 'stable_since': '2025-02-02T16:39:16.079034702Z', 'status': 'non-voter', 'version': '1.16.3', 'node_type': 'voter'}}, 'voters': ['test-integration-tz99-vault-k8s/0', 'test-integration-tz99-vault-k8s/1', 'test-integration-tz99-vault-k8s/2']}
controller-0: 16:41:31 ERROR juju.worker.caasapplicationprovisioner.runner exited "tls-certificates-requirer": more than 20 retries ensuring scale: setting scale to 1 for "tls-certificates-requirer": statefulset "tls-certificates-requirer" not found
controller-0: 16:41:33 ERROR juju.worker.caasapplicationprovisioner.runner exited "self-signed-certificates": more than 20 retries ensuring trust: updating application "self-signed-certificates" to desired trust false: getting service account role "self-signed-certificates": k8s: roles.rbac.authorization.k8s.io "self-signed-certificates" not found
controller-0: 16:42:31 ERROR juju.worker.caasapplicationprovisioner.runner exited "tls-certificates-requirer": more than 20 retries ensuring scale: setting scale to 1 for "tls-certificates-requirer": statefulset "tls-certificates-requirer" not found
controller-0: 16:42:36 ERROR juju.worker.caasapplicationprovisioner.runner exited "self-signed-certificates": more than 20 retries ensuring scale: setting scale to 1 for "self-signed-certificates": statefulset "self-signed-certificates" not found
controller-0: 16:43:32 ERROR juju.worker.caasapplicationprovisioner.runner exited "tls-certificates-requirer": more than 20 retries ensuring scale: setting scale to 1 for "tls-certificates-requirer": statefulset "tls-certificates-requirer" not found
controller-0: 16:43:40 ERROR juju.worker.caasapplicationprovisioner.runner exited "self-signed-certificates": more than 20 retries ensuring trust: updating application "self-signed-certificates" to desired trust false: getting service account role "self-signed-certificates": k8s: roles.rbac.authorization.k8s.io "self-signed-certificates" not found
controller-0: 16:44:35 ERROR juju.worker.caasapplicationprovisioner.runner exited "tls-certificates-requirer": more than 20 retries ensuring trust: updating application "tls-certificates-requirer" to desired trust false: getting service account role "tls-certificates-requirer": k8s: roles.rbac.authorization.k8s.io "tls-certificates-requirer" not found
controller-0: 16:44:43 ERROR juju.worker.caasapplicationprovisioner.runner exited "self-signed-certificates": more than 20 retries ensuring scale: setting scale to 1 for "self-signed-certificates": statefulset "self-signed-certificates" not found
unit-prometheus-k8s-0: 16:57:36 ERROR unit.prometheus-k8s/0.juju-log metrics-endpoint:10: Failed to apply resource limit patch: Unauthorized
unit-prometheus-k8s-0: 16:57:37 ERROR unit.prometheus-k8s/0.juju-log metrics-endpoint:10: Failed to apply resource limit patch: Unauthorized
unit-prometheus-k8s-0: 16:57:40 ERROR unit.prometheus-k8s/0.juju-log metrics-endpoint:10: Failed to apply resource limit patch: Unauthorized
unit-prometheus-k8s-0: 16:57:42 ERROR unit.prometheus-k8s/0.juju-log metrics-endpoint:10: Failed to apply resource limit patch: Unauthorized
unit-prometheus-k8s-0: 16:57:43 ERROR unit.prometheus-k8s/0.juju-log metrics-endpoint:10: Failed to apply resource limit patch: Unauthorized
unit-prometheus-k8s-0: 16:59:07 ERROR unit.prometheus-k8s/0.juju-log Failed to apply resource limit patch: Unauthorized
unit-prometheus-k8s-0: 17:02:49 ERROR juju.worker.uniter pebble poll failed for container "prometheus": failed to send pebble-ready event: terminated
unit-loki-k8s-0: 17:03:12 ERROR unit.loki-k8s/0.juju-log Failed to apply resource limit patch: Unauthorized
unit-loki-k8s-0: 17:03:12 ERROR unit.loki-k8s/0.juju-log Failed to apply resource limit patch: Unauthorized
unit-loki-k8s-0: 17:04:12 ERROR unit.loki-k8s/0.juju-log Failed to apply resource limit patch: Unauthorized
unit-loki-k8s-0: 17:04:12 ERROR juju.worker.uniter pebble poll failed for container "node-exporter": failed to send pebble-ready event: terminated
controller-0: 17:05:56 ERROR juju.worker.caasunitprovisioner stopping application worker for minio: Operation cannot be fulfilled on statefulsets.apps "minio": StorageError: invalid object, Code: 4, Key: /registry/statefulsets/test-integration-tz99/minio, ResourceVersion: 0, AdditionalErrorMsg: Precondition failed: UID in precondition: 694031f1-2f03-4021-8533-0b144f557f2c, UID in object meta: 
unit-vault-b-2: 17:08:59 ERROR unit.vault-b/2.juju-log vault-autounseal-requires:13: Raft cluster is not healthy. {'failure_tolerance': 0, 'healthy': False, 'leader': 'test-integration-tz99-vault-b/0', 'servers': {'test-integration-tz99-vault-b/0': {'id': 'test-integration-tz99-vault-b/0', 'name': 'test-integration-tz99-vault-b/0', 'address': 'vault-b-0.vault-b-endpoints.test-integration-tz99.svc.cluster.local:8201', 'node_status': 'alive', 'last_contact': '0s', 'last_term': 3, 'last_index': 98, 'healthy': True, 'stable_since': '2025-02-02T17:07:12.153006158Z', 'status': 'leader', 'version': '1.16.3', 'node_type': 'voter'}, 'test-integration-tz99-vault-b/1': {'id': 'test-integration-tz99-vault-b/1', 'name': 'test-integration-tz99-vault-b/1', 'address': 'vault-b-1.vault-b-endpoints.test-integration-tz99.svc.cluster.local:8201', 'node_status': 'alive', 'last_contact': '3.828389637s', 'last_term': 0, 'last_index': 0, 'healthy': False, 'stable_since': '2025-02-02T17:08:56.153893239Z', 'status': 'non-voter', 'version': '1.16.3', 'node_type': 'voter'}, 'test-integration-tz99-vault-b/2': {'id': 'test-integration-tz99-vault-b/2', 'name': 'test-integration-tz99-vault-b/2', 'address': 'vault-b-2.vault-b-endpoints.test-integration-tz99.svc.cluster.local:8201', 'node_status': 'alive', 'last_contact': '4.515913004s', 'last_term': 0, 'last_index': 0, 'healthy': False, 'stable_since': '2025-02-02T17:08:54.154199538Z', 'status': 'non-voter', 'version': '1.16.3', 'node_type': 'voter'}}, 'voters': ['test-integration-tz99-vault-b/0']}
unit-vault-b-1: 17:09:01 ERROR unit.vault-b/1.juju-log vault-autounseal-requires:13: Raft cluster is not healthy. {'failure_tolerance': 0, 'healthy': False, 'leader': 'test-integration-tz99-vault-b/0', 'servers': {'test-integration-tz99-vault-b/0': {'id': 'test-integration-tz99-vault-b/0', 'name': 'test-integration-tz99-vault-b/0', 'address': 'vault-b-0.vault-b-endpoints.test-integration-tz99.svc.cluster.local:8201', 'node_status': 'alive', 'last_contact': '0s', 'last_term': 3, 'last_index': 104, 'healthy': True, 'stable_since': '2025-02-02T17:07:12.153006158Z', 'status': 'leader', 'version': '1.16.3', 'node_type': 'voter'}, 'test-integration-tz99-vault-b/1': {'id': 'test-integration-tz99-vault-b/1', 'name': 'test-integration-tz99-vault-b/1', 'address': 'vault-b-1.vault-b-endpoints.test-integration-tz99.svc.cluster.local:8201', 'node_status': 'alive', 'last_contact': '5.828299119s', 'last_term': 0, 'last_index': 0, 'healthy': False, 'stable_since': '2025-02-02T17:08:56.153893239Z', 'status': 'non-voter', 'version': '1.16.3', 'node_type': 'voter'}, 'test-integration-tz99-vault-b/2': {'id': 'test-integration-tz99-vault-b/2', 'name': 'test-integration-tz99-vault-b/2', 'address': 'vault-b-2.vault-b-endpoints.test-integration-tz99.svc.cluster.local:8201', 'node_status': 'alive', 'last_contact': '351.067152ms', 'last_term': 3, 'last_index': 98, 'healthy': True, 'stable_since': '2025-02-02T17:08:54.154199538Z', 'status': 'non-voter', 'version': '1.16.3', 'node_type': 'voter'}}, 'voters': ['test-integration-tz99-vault-b/0']}
unit-vault-b-0: 17:09:26 ERROR unit.vault-b/0.juju-log [vault_client] Error while checking Vault health status: HTTPSConnectionPool(host='vault-b-0.vault-b-endpoints.test-integration-tz99.svc.cluster.local', port=8200): Max retries exceeded with url: /v1/sys/health (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7983eea2d360>: Failed to establish a new connection: [Errno 111] Connection refused'))
unit-vault-b-1: 17:09:53 ERROR unit.vault-b/1.juju-log [vault_client] Error while checking Vault health status: HTTPSConnectionPool(host='vault-b-1.vault-b-endpoints.test-integration-tz99.svc.cluster.local', port=8200): Max retries exceeded with url: /v1/sys/health (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x70d6d4670610>: Failed to establish a new connection: [Errno 111] Connection refused'))
unit-vault-b-0: 17:09:57 ERROR unit.vault-b/0.juju-log [vault_client] Error while checking Vault health status: HTTPSConnectionPool(host='vault-b-0.vault-b-endpoints.test-integration-tz99.svc.cluster.local', port=8200): Max retries exceeded with url: /v1/sys/health (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x771d90174be0>: Failed to establish a new connection: [Errno 111] Connection refused'))
unit-vault-b-2: 17:10:03 ERROR unit.vault-b/2.juju-log [vault_client] Error while checking Vault health status: HTTPSConnectionPool(host='vault-b-2.vault-b-endpoints.test-integration-tz99.svc.cluster.local', port=8200): Max retries exceeded with url: /v1/sys/health (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7ecf8cdfc760>: Failed to establish a new connection: [Errno 111] Connection refused'))
unit-vault-b-2: 17:10:14 ERROR unit.vault-b/2.juju-log Raft cluster is not healthy. {'failure_tolerance': 0, 'healthy': False, 'leader': 'test-integration-tz99-vault-b/1', 'servers': {'test-integration-tz99-vault-b/0': {'id': 'test-integration-tz99-vault-b/0', 'name': 'test-integration-tz99-vault-b/0', 'address': 'vault-b-0.vault-b-endpoints.test-integration-tz99.svc.cluster.local:8201', 'node_status': 'alive', 'last_contact': '4.772892ms', 'last_term': 0, 'last_index': 0, 'healthy': False, 'stable_since': '2025-02-02T17:10:13.331856035Z', 'status': 'voter', 'version': '1.16.3', 'node_type': 'voter'}, 'test-integration-tz99-vault-b/1': {'id': 'test-integration-tz99-vault-b/1', 'name': 'test-integration-tz99-vault-b/1', 'address': 'vault-b-1.vault-b-endpoints.test-integration-tz99.svc.cluster.local:8201', 'node_status': 'alive', 'last_contact': '0s', 'last_term': 4, 'last_index': 239, 'healthy': True, 'stable_since': '2025-02-02T17:10:13.331856035Z', 'status': 'leader', 'version': '1.16.3', 'node_type': 'voter'}, 'test-integration-tz99-vault-b/2': {'id': 'test-integration-tz99-vault-b/2', 'name': 'test-integration-tz99-vault-b/2', 'address': 'vault-b-2.vault-b-endpoints.test-integration-tz99.svc.cluster.local:8201', 'node_status': 'alive', 'last_contact': '4.772511ms', 'last_term': 0, 'last_index': 0, 'healthy': False, 'stable_since': '2025-02-02T17:10:13.331856035Z', 'status': 'voter', 'version': '1.16.3', 'node_type': 'voter'}}, 'voters': ['test-integration-tz99-vault-b/1', 'test-integration-tz99-vault-b/0', 'test-integration-tz99-vault-b/2']}

[32mINFO    [0m pytest_operator.plugin:plugin.py:1041 Resetting model test-integration-tz99...
[32mINFO    [0m pytest_operator.plugin:plugin.py:1030    Destroying applications vault-k8s
[32mINFO    [0m pytest_operator.plugin:plugin.py:1030    Destroying applications vault-b
[32mINFO    [0m pytest_operator.plugin:plugin.py:1046 Not waiting on reset to complete.
[32mINFO    [0m pytest_operator.plugin:plugin.py:1017 Forgetting model main...